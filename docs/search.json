[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "spatial data ugur ursavas xxxx",
    "section": "",
    "text": "Welcome\nThis is the website for “Web Mapping and Geovisualisation” (module ENVS456) at the University of Liverpool. This course is designed and delivered by Dr. Gabriele Filomena and Dr. Elisabetta Pietrostefani from the Geographic Data Science Lab at the University of Liverpool, United Kingdom. The module has two main aims. It seeks to provide hands-on experience and training in:\nThe website is free to use and is licensed under the Attribution-NonCommercial-NoDerivatives 4.0 International. A compilation of this web course is hosted as a GitHub repository that you can access:",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "spatial data ugur ursavas xxxx",
    "section": "Contact",
    "text": "Contact\n\nUgur Ursavas - gfilo [at] liverpool.ac.uk Lecturer in Geographic Data Science Office 1xx, Roxby Building, University of Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, United Kingdom.\n\n\nElisabetta Pietrostefani - e.pietrostefani [at] liverpool.ac.uk Lecturer in Geographic Data Science Office 6xx, Roxby Building, University of Liverpool - 74 Bedford St S, Liverpool, L69 7ZT, United Kingdom.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "general/overview.html",
    "href": "general/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Aims\nThis module aims to provide hands-on experience and training in: - The design and generation of (good looking) web-based mapping and geographical information tools. - The use of software to access, analyse and visualize web-based geographical information.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "general/overview.html#learning-outcomes",
    "href": "general/overview.html#learning-outcomes",
    "title": "Overview",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of the module, students should be able to:\n\nVisualise and represent geo-data through static and dynamic maps.\nRecognise and describe the component of web based mapping infrastructure.\nCollect Web-based data.\nGenerate interactive maps and dashboards.\nUnderstand basic concepts of spatial network analysis.\nManipulate geo-data through scripting in Python.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "general/overview.html#feedback",
    "href": "general/overview.html#feedback",
    "title": "Overview",
    "section": "Feedback",
    "text": "Feedback\nFormal assessment. Two pieces of coursework (50%/50%). Equivalent to 2,500 words each\nVerbal face-to-face feedback. Immediate face-to-face feedback will be provided during computer, discussion and clinic sessions in interaction with staff. This will take place in all live sessions during the semester. Teams Forum. Asynchronous written feedback will be provided via Teams. Students are encouraged to contribute by asking and answering questions relating to the module content. Staff will monitor the forum Monday to Friday 9am-5pm, but it will be open to students to make contributions at all times. Response time will vary depending on the complexity of the question and staff availability.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "labs/w01_intro.html",
    "href": "labs/w01_intro.html",
    "title": "1  Introduction & Python Refresher",
    "section": "",
    "text": "1.1 Part I: Powerful Web Mapping Examples\nThis part of the lab has two main components: 1. The first one will require you to find a partner and work together with her/him 2. And the second one will involve group discussion.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w01_intro.html#part-i-powerful-web-mapping-examples",
    "href": "labs/w01_intro.html#part-i-powerful-web-mapping-examples",
    "title": "1  Introduction & Python Refresher",
    "section": "",
    "text": "1.1.1 Paired Activity\nIn pairs, find three examples where web maps are used to communicate an idea. Complete the following sheet for each example:\n\nSubstantive\n\nTitle: Title of the map/project\nAuthor: Who is behind the project?\nBig idea: a “one-liner” on what the project tries to accomplish –\nMessage: what does the map try to get accross\n\nTechnical\n\nURL:\nInteractivity: does the map let you interact with it in any way? Yes/No\nZoomable: can you explore the map at different scales? Yes/No\nTooltips:\nBasemap: Is there an underlying map providing geographical context? Yes/No. If so, who is it provided by?\nTechnology: can you guess what technology does this map rely on?\n\n\nPost each sheet as a separate item on the Teams channel for Lab No.1\n\n1.1.1.1 Example\nThe project “WHO Coronavirus (COVID-19) Dashboard”\n\n\nSubstantive\n\nTitle: WHO Coronavirus (COVID-19) Dashboard\nAuthor: World Health Organization\nBig idea: Shows confirmed COVID-19 cases and deaths by country to date\nMessage: The project displays a map of the world where COVID-19 cases are shown by country. This element is used to show which countries have had more cases (large trends). A drop down button allows us to visualise the map by a) Total per 100,000 population b) % change in the last 7 days c) newly reported in the last 7 days d) newly reported in the last 24 hours.\n\nTechnical\n\nURL: https://covid19.who.int/\nInteractivity: Yes\nZoomable: Yes\nTooltips: Yes\nBasemap: No\nTechnology: Unknown\n\n\nHere are a couple of other COVID-19 examples of web-maps that where basemaps and technology is easier to spot.\n\n“London School of Hygiene & Tropical Medicine - COVID-19 tracker”\n“Tracking Coronavirus in the United Kingdom: Latest Map and Case Count”\n\n\n\n\n1.1.2 Class discussion\nWe will select a few examples posted and collectively discuss (some of) the following questions:\n\nWhat makes them powerful, what “speaks” to us?\nWhat could be improved, what is counter-intuitive?\nWhat design elements do they rely on?\nWhat technology do they use?\n\n\n\n1.1.3 References\n\nFor an excellent coverage of “visualisation literacy”, Chapter 11 of Andy Kirk’s “Data Visualisation” is a great start. Lab: Getting up to speed for web mapping\nA comprehensive overview of computational notebooks and how they relate to modern scientific work is available on Ch.1 of the GDS book.\nA recent overview of notebooks in Geography is available in Boeing & Arribas-Bel (2021)",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w01_intro.html#part-ii-pythonpandas-refresher",
    "href": "labs/w01_intro.html#part-ii-pythonpandas-refresher",
    "title": "1  Introduction & Python Refresher",
    "section": "1.2 Part II: Python/Pandas (Refresher)",
    "text": "1.2 Part II: Python/Pandas (Refresher)\nGabriele Filomena has prepared this notebook by readapting material shared on this repository. Copyright (c) 2013-2023 Geoff Boeing.\n\n1.2.1 Python\nA quick overview of ubiquitous programming concepts including data types, for loops, if-then-else conditionals, and functions.\n\nimport numpy as np\nimport pandas as pd\n\n\n# integers (int)\nx = 100\ntype(x)\n\n\n# floating-point numbers (float)\nx = 100.5\ntype(x)\n\n\n# sequence of characters (str)\nx = 'Los Angeles, CA 90089'\nlen(x)\n\n\n# list of items\nx = [1, 2, 3, 'USC']\nlen(x)\n\n\n# sets are unique\nx = {2, 2, 3, 3, 1}\nx\n\n\n# tuples are immutable sequences\nlatlng = (34.019425, -118.283413)\ntype(latlng)\n\n\n# you can unpack a tuple\nlat, lng = latlng\ntype(lat)\n\n\n# dictionary of key:value pairs\niceland = {'Country': 'Iceland', 'Population': 372520, 'Capital': 'Reykjavík', '% Foreign Population' : 0.18 }\ntype(iceland)\n\n\n# you can convert types\nx = '100'\nprint(type(x))\ny = int(x)\nprint(type(y))\n\n\n# you can loop through an iterable, such as a list or tuple\nfor coord in latlng:\n    print('Current coordinate is:', coord)\n\n\n# loop through a dictionary keys and values as tuples\nfor key, value in iceland.items():\n    print(key, value)\n\n\n# booleans are trues/falses\nx = 101\nx &gt; 100\n\n\n# use two == for equality and one = for assignment\nx == 100\n\n\n# if, elif, else for conditional branching execution\nx = 101\nif x &gt; 100:\n    print('Value is greater than 100.')\nelif x &lt; 100:\n    print('Value is less than 100.')\nelse:\n    print('Value is 100.')\n\n\n# use functions to encapsulate and reuse bits of code\ndef convert_items(my_list, new_type=str):\n    # convert each item in a list to a new type\n    new_list = [new_type(item) for item in my_list]\n    return new_list\n\nl = [1, 2, 3, 4]\nconvert_items(l)\n\n\n\n1.2.2 pandas Series and DataFrames\npandas has two primary data structures we will work with: Series and DataFrame.\n\n1.2.2.1 Pandas Series\n\n# a pandas series is based on a numpy array: it's fast, compact, and has more functionality\n# it has an index which allows you to work naturally with tabular data\nmy_list = [8, 5, 77, 2]\nmy_series = pd.Series(my_list)\nmy_series\n\n\n# look at a list-representation of the index\nmy_series.index.tolist()\n\n\n# look at the series' values themselves\nmy_series.values\n\n\n# what's the data type of the series' values?\ntype(my_series.values)\n\n\n# what's the data type of the individual values themselves?\nmy_series.dtype\n\n\n\n1.2.2.2 Pandas DataFrames\n\n# a dict can contain multiple lists and label them\nmy_dict = {'hh_income'  : [75125, 22075, 31950, 115400],\n           'home_value' : [525000, 275000, 395000, 985000]}\nmy_dict\n\n\n# a pandas dataframe can contain one or more columns\n# each column is a pandas series\n# each row is a pandas series\n# you can create a dataframe by passing in a list, array, series, or dict\ndf = pd.DataFrame(my_dict)\ndf\n\n\n# the row labels in the index are accessed by the .index attribute of the DataFrame object\ndf.index.tolist()\n\n\n# the column labels are accessed by the .columns attribute of the DataFrame object\ndf.columns\n\n\n# the data values are accessed by the .values attribute of the DataFrame object\n# this is a numpy (two-dimensional) array\ndf.values\n\n\n\n\n1.2.3 Loading data in Pandas\nUsually, you’ll work with data by loading a dataset file into pandas. CSV is the most common format. But pandas can also ingest tab-separated data, JSON, and proprietary file formats like Excel .xlsx files, Stata, SAS, and SPSS.\nBelow, notice what pandas’s read_csv function does:\n\nRecognize the header row and get its variable names.\nRead all the rows and construct a pandas DataFrame (an assembly of pandas Series rows and columns).\nConstruct a unique index, beginning with zero.\nInfer the data type of each variable (i.e., column).\n\n\n# load a data file\n# note the relative filepath! where is this file located?\n# use dtype argument if you don't want pandas to guess your data types\ndf = pd.read_csv('../data/GTD_2022.csv', low_memory = False)\n\n\nto_replace = [-9, -99, \"-9\", \"-99\"]\nfor value in to_replace:\n    df = df.replace(value, np.NaN)\n\ndf['eventid'] = df['eventid'].astype(\"Int64\")\n\n\n# dataframe shape as rows, columns\ndf.shape\n\n\n# or use len to just see the number of rows\nlen(df)\n\n\n# view the dataframe's \"head\"\ndf.head()\n\n\n# view the dataframe's \"tail\"\ndf.tail()\n\n\n# column data types\ndf.dtypes\n\n\n# or\nfor dt in df.columns[:10]:\n    print(dt, type(dt))\n\n\n\n1.2.4 Selecting and slicing data from a DataFrame\n\n# CHEAT SHEET OF COMMON TASKS\n# Operation                       Syntax           Result\n#------------------------------------------------------------\n# Select column by name           df[col]          Series\n# Select columns by name          df[col_list]     DataFrame\n# Select row by label             df.loc[label]    Series\n# Select row by integer location  df.iloc[loc]     Series\n# Slice rows by label             df.loc[a:c]      DataFrame\n# Select rows by boolean vector   df[mask]         DataFrame\n\n\n1.2.4.1 Select DataFrame’s column(s) by name\n\n# select a single column by column name\n# this is a pandas series\ndf['country']\n\n\n# select multiple columns by a list of column names\n# this is a pandas dataframe that is a subset of the original\ndf[['country_txt', 'year']]\n\n\n# create a new column by assigning df['new_col'] to some values\n# people killed every perpetrator \ndf['killed_per_attacker'] = df['nkill'] / df['nperps']\n\n# inspect the results\ndf[['country', 'year', 'nkill', 'nperps', 'killed_per_attacker']].head(15)\n\n\n\n1.2.4.2 Select row(s) by label\n\n# use .loc to select by row label\n# returns the row as a series whose index is the dataframe column names\ndf.loc[0]\n\n\n# use .loc to select single value by row label, column name\ndf.loc[15, 'gname'] #group name\n\n\n# slice of rows from label 5 to label 7, inclusive\n# this returns a pandas dataframe\ndf.loc[5:7]\n\n\n# slice of rows from label 17 to label 27, inclusive\n# slice of columns from country_txt to city, inclusive\ndf.loc[17:27, 'country_txt':'city']\n\n\n# subset of rows from with labels in list\n# subset of columns with names in list\ndf.loc[[1, 350], ['country', 'gname']]\n\n\n# you can use a column of identifiers as the index (indices do not *need* to be unique)\ndf_gname = df.set_index('gname')\ndf_gname.index.is_unique\n\n\ndf_gname.head(3)\n\n\n# .loc works by label, not by position in the dataframe\ntry:\n    df_gname.loc[0]\nexcept KeyError as e:\n    print('label not found')\n\n\n# the index now contains gname values, so you have to use .loc accordingly to select by row label\ndf_gname.loc['Taliban'].head()\n\n\n\n1.2.4.3 Select by (integer) position - Independent from actual Index\n\n# get the row in the zero-th position in the dataframe\ndf.iloc[0]\n\n\n# you can slice as well\n# note, while .loc is inclusive, .iloc is not\n# get the rows from position 0 up to but not including position 3 (ie, rows 0, 1, and 2)\ndf.iloc[0:3]\n\n\n# get the value from the row in position 3 and the column in position 2 (zero-indexed)\ndf.iloc[3, 6] #country_txt\n\n\n\n1.2.4.4 Select/filter by value\nYou can subset or filter a dataframe for based on the values in its rows/columns.\n\n# filter the dataframe by urban areas with more than 25 million residents\ndf[df['nkill'] &gt; 30].head()\n\n\n# you can chain multiple conditions together\n# pandas logical operators are: | for or, & for and, ~ for not\n# these must be grouped by using parentheses due to order of operations\ndf[['country','nkill', 'nwound']][(df['nkill'] &gt; 200) & (df['nwound'] &gt; 10)].head()\n# columns on the left-hand side are here used to slice the resulting output\n\n\n# ~ means not... it essentially flips trues to falses and vice-versa\ndf[['country','nkill', 'nwound']][~(df['nkill'] &gt; 200) & (df['nwound'] &gt; 10)]\n\n\n\n\n1.2.5 Grouping and summarizing\n\n# group by terroristic group name\ngroups = df.groupby('gname')\n\n\n# what is the median number of people killed per event across the different groups?\ngroups['nkill'].median().sort_values(ascending=False)\n\n\n# look at several columns' medians by group\ngroups[['nkill', 'nwound', 'nperps']].median()\n\n\n# you can create a new dataFrame by directly passing columns between \"[[ ]]\", after the groupby function\n# to do so, you also need to pass a function that can deal with the values (e.g. sum..etc) \nwestern_europe = df[df.region_txt == 'Western Europe']\nwestern_europe.groupby('country_txt')[['nkill', 'nwound']].sum().sort_values('nkill', ascending = False).reset_index()\n\n\n\n1.2.6 Indexes\nEach DataFrame has an index. Indexes do not have to be unique (but that would be for the best)\n\n# resetting index (when loading a .csv file pandas creates an index automatically, from 0 to Nrecords-1)\ndf.reset_index(drop = True).sort_index().head() # this does not assign the new index though, it just shows you a temp copy\n\n\n#this does assign the new index to your df\ndf = df.reset_index(drop = True).sort_index() \ndf.head()\n\n\n# index isn't unique\ndf.index.is_unique\n\n\n# you can set a new index\n# drop -&gt; Delete columns to be used as the new index.\n# append -&gt;  whether to append columns to existing index.\ndf = df.set_index('eventid', drop=True, append=False)\ndf.index.name = None # remove the index \"name\"\ndf.head()\n\n# this index is not ideal, but it's the original source's id",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w01_intro.html#part-iii-geospatial-vector-data-in-python",
    "href": "labs/w01_intro.html#part-iii-geospatial-vector-data-in-python",
    "title": "1  Introduction & Python Refresher",
    "section": "1.3 Part III: Geospatial Vector data in Python",
    "text": "1.3 Part III: Geospatial Vector data in Python\nGabriele Filomena has prepared this notebook by readapting material shared on this repository. Copyright (c) 2018, Joris Van den Bossche.\n\n%matplotlib inline\n\nimport geopandas as gpd\n\n\n1.3.1 Importing geospatial data\nGeoPandas builds on Pandas types Series and Dataframe, by incorporating information about geographical space.\n\nGeoSeries: a Series object designed to store shapely geometry object\nGeoDataFrame: object is a pandas DataFrame that has a column with geometry (that contains a Geoseries)\n\nWe can use the GeoPandas library to read many of GIS file formats (relying on the fiona library under the hood, which is an interface to GDAL/OGR), using the gpd.read_file function. For example, let’s start by reading a shapefile with all the countries of the world (adapted from http://www.naturalearthdata.com/downloads/110m-cultural-vectors/110m-admin-0-countries/, zip file is available in the /data directory), and inspect the data:\n\ncountries = gpd.read_file(\"../data/ne_countries.zip\")\n# or if the archive is unpacked:\n# countries = gpd.read_file(\"../data/ne_countries.shp\")\n\n\ncountries.head()\n\n\ncountries.plot()\n\nWe observe that:\n\nUsing .head() we can see the first rows of the dataset, just like we can do with Pandas.\nThere is a geometry column and the different countries are represented as polygons\nWe can use the .plot() (matplotlib) method to quickly get a basic visualization of the data\n\n\n\n1.3.2 What’s a GeoDataFrame?\nWe used the GeoPandas library to read in the geospatial data, and this returned us a GeoDataFrame:\n\ntype(countries)\n\nA GeoDataFrame contains a tabular, geospatial dataset:\n\nIt has a ‘geometry’ column that holds the geometry information (or features in GeoJSON).\nThe other columns are the attributes (or properties in GeoJSON) that describe each of the geometries.\n\nSuch a GeoDataFrame is just like a pandas DataFrame, but with some additional functionality for working with geospatial data: * A geometry attribute that always returns the column with the geometry information (returning a GeoSeries). The column name itself does not necessarily need to be ‘geometry’, but it will always be accessible as the geometry attribute. * It has some extra methods for working with spatial data (area, distance, buffer, intersection, …) see here, for example.\n\ncountries.geometry.head()\n\n\ntype(countries.geometry)\n\n\ncountries.geometry.area\n\nIt’s still a DataFrame, so we have all the pandas functionality available to use on the geospatial dataset, and to do data manipulations with the attributes and geometry information together. For example, we can calculate the average population over all countries (by accessing the ‘pop_est’ column, and calling the mean method on it):\n\ncountries['pop_est'].mean()\n\n\nafrica = countries[countries['continent'] == 'Africa']\n\n\nafrica.plot();\n\nThe rest of the tutorial is going to assume you already know some pandas basics, but we will try to give hints for that part for those that are not familiar.\n\nImportant: \n\nA GeoDataFrame allows to perform typical tabular data analysis together with spatial operations\nA GeoDataFrame (or Feature Collection) consists of:\n\nGeometries or features: the spatial objects\nAttributes or properties: columns with information about each spatial object\n\n\n\n\n\n1.3.3 Geometries: Points, Linestrings and Polygons\nSpatial vector data can consist of different types, and the 3 fundamental types are:\n\n\nPoint data: represents a single point in space.\nLine data (“LineString”): represented as a sequence of points that form a line.\nPolygon data: represents a filled area.\n\nAnd each of them can also be combined in multi-part geometries (See https://shapely.readthedocs.io/en/stable/manual.html#geometric-objects for extensive overview).\nFor the example we have seen up to now, the individual geometry objects are Polygons:\n\nprint(countries.geometry[2])\n\nLet’s import some other datasets with different types of geometry objects.\nA dateset about cities in the world (adapted from http://www.naturalearthdata.com/downloads/110m-cultural-vectors/110m-populated-places/, zip file is available in the /data directory), consisting of Point data:\n\ncities = gpd.read_file(\"../data/ne_cities.zip\")\n\n\nprint(cities.geometry[0])\n\nAnd a dataset of rivers in the world (from http://www.naturalearthdata.com/downloads/50m-physical-vectors/50m-rivers-lake-centerlines/, zip file is available in the /data directory) where each river is a (Multi-)LineString:\n\nrivers = gpd.read_file(\"../data/ne_rivers.zip\")\n\n\nprint(rivers.geometry[0])\n\n\n\n1.3.4 The shapely library\nThe individual geometry objects are provided by the shapely library\n\nfrom shapely.geometry import Point, Polygon, LineString\n\n\ntype(countries.geometry[0])\n\nTo construct one ourselves:\n\np = Point(0, 0)\n\n\nprint(p)\n\n\npolygon = Polygon([(1, 1), (2,2), (2, 1)])\n\n\npolygon.area\n\n\npolygon.distance(p)\n\n\nImportant: \nSingle geometries are represented by shapely objects:\n\nIf you access a single geometry of a GeoDataFrame, you get a shapely geometry object\nThose objects have similar functionality as geopandas objects (GeoDataFrame/GeoSeries). For example:\n\nsingle_shapely_object.distance(other_point) -&gt; distance between two points\ngeodataframe.distance(other_point) -&gt; distance for each point in the geodataframe to the other point\n\n\n\n\n\n1.3.5 Plotting\n\n%matplotlib inline\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(1, 1, figsize=(15, 10))\ncountries.plot(ax = ax, edgecolor='k', facecolor='none')\nrivers.plot(ax=ax)\ncities.plot(ax=ax, color='red')\nax.set(xlim=(-20, 60), ylim=(-40, 40))\n\n\n\n1.3.6 Creating GeoDataFrames (withouth specifying the CRS)\n\ngpd.GeoDataFrame({\n    'geometry': [Point(1, 1), Point(2, 2)],\n    'attribute1': [1, 2],\n    'attribute2': [0.1, 0.2]})\n\n\n# Creating a GeoDataFrame from an existing dataframe\n# For example, if you have lat/lon coordinates in two columns:\ndf = pd.DataFrame(\n    {'City': ['Buenos Aires', 'Brasilia', 'Santiago', 'Bogota', 'Caracas'],\n     'Country': ['Argentina', 'Brazil', 'Chile', 'Colombia', 'Venezuela'],\n     'Latitude': [-34.58, -15.78, -33.45, 4.60, 10.48],\n     'Longitude': [-58.66, -47.91, -70.66, -74.08, -66.86]})\n\n\ngdf = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.Longitude, df.Latitude))\ngdf",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w01_intro.html#part-iv-coordinate-reference-systems-projections",
    "href": "labs/w01_intro.html#part-iv-coordinate-reference-systems-projections",
    "title": "1  Introduction & Python Refresher",
    "section": "2.1 Part IV: Coordinate reference systems & Projections",
    "text": "2.1 Part IV: Coordinate reference systems & Projections\nGabriele Filomena has prepared this notebook by readapting material shared on this repository. Copyright (c) 2018, Joris Van den Bossche.\n\ncountries = gpd.read_file(\"../data/ne_countries.zip\")\ncities = gpd.read_file(\"../data/ne_cities.zip\")\nrivers = gpd.read_file(\"../data/ne_rivers.zip\")\n\n\n2.1.1 Coordinate reference systems\nUp to now, we have used the geometry data with certain coordinates without further wondering what those coordinates mean or how they are expressed.\n\nThe Coordinate Reference System (CRS) relates the coordinates to a specific location on earth.\n\nFor an in-depth explanation, see https://docs.qgis.org/2.8/en/docs/gentle_gis_introduction/coordinate_reference_systems.html\n\n2.1.1.1 Geographic coordinates\n\nDegrees of latitude and longitude.\nE.g. 48°51′N, 2°17′E\n\nThe most known type of coordinates are geographic coordinates: we define a position on the globe in degrees of latitude and longitude, relative to the equator and the prime meridian. With this system, we can easily specify any location on earth. It is used widely, for example in GPS. If you inspect the coordinates of a location in Google Maps, you will also see latitude and longitude.\nAttention!\nin Python we use (lon, lat) and not (lat, lon)\n\nLongitude: [-180, 180]{{1}}\nLatitude: [-90, 90]{{1}}\n\n\n\n\n2.1.2 Projected coordinates\n\n(x, y) coordinates are usually in meters or feet\n\nAlthough the earth is a globe, in practice we usually represent it on a flat surface: think about a physical map, or the figures we have made with Python on our computer screen. Going from the globe to a flat map is what we call a projection.\n\nWe project the surface of the earth onto a 2D plane so we can express locations in cartesian x and y coordinates, on a flat surface. In this plane, we then typically work with a length unit such as meters instead of degrees, which makes the analysis more convenient and effective.\nHowever, there is an important remark: the 3 dimensional earth can never be represented perfectly on a 2 dimensional map, so projections inevitably introduce distortions. To minimize such errors, there are different approaches to project, each with specific advantages and disadvantages.\nSome projection systems will try to preserve the area size of geometries, such as the Albers Equal Area projection. Other projection systems try to preserve angles, such as the Mercator projection, but will see big distortions in the area. Every projection system will always have some distortion of area, angle or distance.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProjected size vs actual size (Mercator projection): \n\n\n2.1.3 Coordinate Reference Systems in Python / GeoPandas\nA GeoDataFrame or GeoSeries has a .crs attribute which holds (optionally) a description of the coordinate reference system of the geometries:\n\ncountries.crs\n\nFor the countries dataframe, it indicates that it uses the EPSG 4326 / WGS84 lon/lat reference system, which is one of the most used for geographic coordinates.\nIt uses coordinates as latitude and longitude in degrees, as can you be seen from the x/y labels on the plot:\n\ncountries.plot()\n\nThe .crs attribute returns a pyproj.CRS object. To specify a CRS, we typically use some string representation:\n\nEPSG code Example: EPSG:4326 = WGS84 geographic CRS (longitude, latitude)\n\nFor more information, see also http://geopandas.readthedocs.io/en/latest/projections.html.\n\n2.1.3.1 Transforming to another CRS\nWe can convert a GeoDataFrame to another reference system using the to_crs function.\nFor example, let’s convert the countries to the World Mercator projection (http://epsg.io/3395):\n\n# remove Antartica, as the Mercator projection cannot deal with the poles\ncountries = countries[(countries['name'] != \"Antarctica\")]\ncountries_mercator = countries.to_crs(epsg=3395)  # or .to_crs(\"EPSG:3395\")\ncountries_mercator.plot()\n\nNote the different scale of x and y.\n\n\n2.1.3.2 Why using a different CRS?\nThere are sometimes good reasons you want to change the coordinate references system of your dataset, for example:\n\nDifferent sources with different CRS -&gt; need to convert to the same crs.\n\nDifferent countries/geographical areas with different CRS.\nMapping (distortion of shape and distances).\nDistance / area based calculations -&gt; ensure you use an appropriate projected coordinate system expressed in a meaningful unit such as meters or feet (not degrees!).\n\n\nImportant:\nAll the calculations (e.g. distance, spatial operations, etc.) that take place in GeoPandas and Shapely assume that your data is represented in a 2D cartesian plane, and thus the result of those calculations will only be correct if your data is properly projected.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/w01_intro.html#practice-1",
    "href": "labs/w01_intro.html#practice-1",
    "title": "1  Introduction & Python Refresher",
    "section": "2.2 Practice",
    "text": "2.2 Practice\nAgain, we will go back to the Paris datasets. Up to now, we provided the datasets in an appropriate projected CRS for the exercises. But the original data were actually using geographic coordinates. In the following exercises, we will start from there.\nGoing back to the Paris districts dataset, this is now provided as a GeoJSON file (\"../data/paris_districts.geojson\") in geographic coordinates.\nFor converting the layer to projected coordinates, we will use the standard projected CRS for France is the RGF93 / Lambert-93 reference system, referenced by the EPSG:2154 number.\n\nExercise: Projecting a GeoDataFrame\n\nRead the districts datasets (../data/paris_districts.geojson\") into a GeoDataFrame called districts.\nLook at the CRS attribute of the GeoDataFrame. Do you recognize the EPSG number?\nMake a plot of the districts dataset.\nCalculate the area of all districts.\nConvert the districts to a projected CRS (using the EPSG:2154 for France). Call the new dataset districts_RGF93.\nMake a similar plot of districts_RGF93.\nCalculate the area of all districts again with districts_RGF93 (the result will now be expressed in m²).\n\n\n\nHints\n\n\nThe CRS information is stored in the .crs attribute of a GeoDataFrame.\nMaking a simple plot of a GeoDataFrame can be done with the .plot() method.\nConverting to a different CRS can be done with the .to_crs() method, and the CRS can be specified as an EPSG number using the epsg keyword.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction & Python Refresher</span>"
    ]
  },
  {
    "objectID": "labs/panel_w_lags.html",
    "href": "labs/panel_w_lags.html",
    "title": "2  Panel spatial lags",
    "section": "",
    "text": "2.1 Data\nNote we drop the names as they’re irrelevant here (we have unique IDs) and index the table on region ID and year. The resulting table contains only the variables to lag as columns.\npanel = (\n    pandas.read_csv(\n        'spatial_lag_panel_data.csv', \n        encoding = 'ISO-8859-9' # Turkish encoding\n    )\n    .set_index(['asdf_id', 'year'])\n    .drop(columns=['shapeName'])\n)\ngeo = geopandas.read_file('TUR_ADM1.geojson').set_index('asdf_id')\n\nERROR 1: PROJ: proj_create_from_database: Open of /opt/conda/envs/gds/share/proj failed",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Panel spatial lags</span>"
    ]
  },
  {
    "objectID": "labs/panel_w_lags.html#data",
    "href": "labs/panel_w_lags.html#data",
    "title": "2  Panel spatial lags",
    "section": "",
    "text": "Tabular data\n\n\n\n\nGeographic data",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Panel spatial lags</span>"
    ]
  },
  {
    "objectID": "labs/panel_w_lags.html#lag-computation",
    "href": "labs/panel_w_lags.html#lag-computation",
    "title": "2  Panel spatial lags",
    "section": "2.2 Lag computation",
    "text": "2.2 Lag computation\nFirst, we compute the spatial weights we will use. In this example, we pick queen contiguity, although other criteria are available and possibly valid too.\n\nw = (\n    graph.Graph.build_contiguity(geo, rook=False)\n    .transform('R')\n)\n\nNow we’re ready to compute the lags. We approach this as a nested for loop, where we iterate through every year and, within that, through every variable. To make computation more efficient, we first generate the frame where results will be stored (lags).\n\nlags = pandas.DataFrame(index=panel.index, columns=panel.columns)\n\nfor year in panel.index.get_level_values('year').unique():\n    for var in lags.columns:\n        vals = panel.loc[pandas.IndexSlice[:, year], var]\n        lags.loc[vals.index, var] = w.lag(vals)\n\nWe can now write the lagged values to disk:\n\nlags.to_csv('lagged.csv')",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Panel spatial lags</span>"
    ]
  },
  {
    "objectID": "labs/dani_style_informal.html",
    "href": "labs/dani_style_informal.html",
    "title": "3  Build a queen contiguity matrix from a regular 3x3",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nsns.set_context(context=\"paper\", font_scale=1.5, rc=None)\nsns.set(font=\"serif\")\nimport seaborn\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nimport libpysal\nfrom libpysal  import weights\nfrom pysal.explore import esda \nimport esda\nfrom esda.moran import Moran, Moran_Local\n\nimport splot\nfrom splot.esda import moran_scatterplot, plot_moran, lisa_cluster\nfrom splot.libpysal import plot_spatial_weights\n\nfrom giddy.directional import Rose\nimport os\n\nimport contextily\n\n\n\n\nfrom numpy.random import seed\nseed(12345678)\n\n\nos.chdir('F:/projects/2024/informal')\n\n\ngeojson_data = gpd.read_file(\"F:/projects/2024/informal/merged2.geojson\")\n\n\ngeojson_data\n\n\n\n\n\n\n\n\nid\nLevel_x\nasdf_id\ngqid_x\nshapeGroup_x\nshapeID_x\nshapeISO_x\nshapeName_x\nshapeType_x\nLevel_y\n...\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\ngeometry\n\n\n\n\n0\n0\nADM1\n0\n0\nTUR\nTUR-ADM1-80719077B77822815\nTR-01\nAdana\nADM1\nADM1\n...\n29.074056\n28.879486\n28.717164\n28.164996\n28.065424\n28.169607\n28.032190\n27.962083\n27.963184\nMULTIPOLYGON (((35.38791 36.55628, 35.38883 36...\n\n\n1\n1\nADM1\n1\n1\nTUR\nTUR-ADM1-80719077B28599679\nTR-02\nAdıyaman\nADM1\nADM1\n...\n30.463650\n30.191129\n30.059005\n29.584176\n29.437475\n29.383753\n29.370084\n29.405895\n29.467049\nPOLYGON ((37.86100 37.46666, 37.87451 37.46648...\n\n\n2\n2\nADM1\n2\n2\nTUR\nTUR-ADM1-80719077B84550223\nTR-03\nAfyonkarahisar\nADM1\nADM1\n...\n29.410471\n29.017960\n28.868278\n28.304597\n28.053987\n28.197262\n28.100381\n28.123544\n28.388501\nPOLYGON ((30.48061 38.19903, 30.49275 38.19655...\n\n\n3\n3\nADM1\n3\n3\nTUR\nTUR-ADM1-80719077B65173278\nTR-04\nAğrı\nADM1\nADM1\n...\n31.092032\n30.920681\n30.768355\n30.133650\n30.046928\n30.068672\n29.956799\n29.893529\n30.042331\nPOLYGON ((43.77542 39.25004, 43.79639 39.26875...\n\n\n4\n4\nADM1\n4\n4\nTUR\nTUR-ADM1-80719077B72380009\nTR-05\nAmasya\nADM1\nADM1\n...\n29.149678\n28.972973\n28.654526\n28.104956\n28.049226\n28.235330\n28.133426\n28.160648\n28.537311\nPOLYGON ((36.38780 40.66228, 36.39811 40.67508...\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n76\n76\nADM1\n76\n76\nTUR\nTUR-ADM1-80719077B83749854\nTR-77\nYalova\nADM1\nADM1\n...\n27.540859\n27.064284\n26.782969\n26.344062\n26.303003\n26.182438\n26.271476\n26.056398\n25.600179\nPOLYGON ((29.48180 40.56397, 29.48439 40.56645...\n\n\n77\n77\nADM1\n77\n77\nTUR\nTUR-ADM1-80719077B67647683\nTR-66\nYozgat\nADM1\nADM1\n...\n29.867141\n29.399657\n29.236928\n28.653018\n28.719645\n28.762025\n28.810795\n28.693756\n29.061970\nPOLYGON ((35.33995 40.25508, 35.28463 40.22667...\n\n\n78\n78\nADM1\n78\n78\nTUR\nTUR-ADM1-80719077B51620989\nTR-67\nZonguldak\nADM1\nADM1\n...\n29.217234\n28.751137\n28.687704\n28.219806\n27.815600\n27.735502\n28.050741\n27.833101\n27.468281\nMULTIPOLYGON (((31.85365 41.00830, 31.88498 41...\n\n\n79\n79\nADM1\n79\n79\nTUR\nTUR-ADM1-80719077B759750\nTR-73\nŞırnak\nADM1\nADM1\n...\n30.253428\n29.952221\n29.914243\n29.527439\n29.044468\n29.077574\n28.946730\n28.869628\n28.986277\nPOLYGON ((43.49919 37.74179, 43.43868 37.74784...\n\n\n80\n80\nADM1\n80\n80\nTUR\nTUR-ADM1-80719077B19552530\nTR-63\nŞanlıurfa\nADM1\nADM1\n...\n30.772608\n30.571467\n30.396766\n29.958338\n29.780211\n29.893150\n29.881453\n29.929674\n30.030058\nPOLYGON ((38.02504 36.83034, 38.02829 36.83268...\n\n\n\n\n81 rows × 37 columns\n\n\n\n\ngeojson_data['coords'] = geojson_data['geometry'].apply(lambda x: x.representative_point().coords[:])\ngeojson_data['coords'] = [coords[0] for coords in geojson_data['coords']]\n\n\nfig, ax = plt.subplots(figsize=(14,8))\ngeojson_data.plot(column=\"2004\", scheme='NaturalBreaks', k=5, cmap='coolwarm', legend=True, legend_kwds={'title': '', 'bbox_to_anchor':(1.03, 0.96)}, ax=ax)\nplt.title('Spatial distribution of  informal economy (%GDP) in 2004: Five natural breaks')\nfor idx, row in fig, ax = plt.subplots(figsize=(14,8))\nmerged_data.plot(column=\"2004\", scheme='NaturalBreaks', k=5, cmap='coolwarm', legend=True, legend_kwds={'title': '', 'bbox_to_anchor':(1.03, 0.96)}, ax=ax)\nplt.title('Spatial distribution of  informal economy (%GDP) in 2004: Five natural breaks')\nfor idx, row in merged_data.iterrows():\n    ax.annotate(text=row['province'], xy=row['coords'], fontsize=10,\n                 horizontalalignment='center', bbox={'facecolor': 'white', 'alpha':0.8, 'pad': 2, 'edgecolor':'none'})\n\n\nplt.tight_layout()\nax.axis(\"off\")\n\nplt.show().iterrows():\n    ax.annotate(text=row['province'], xy=row['coords'], fontsize=10,\n                 horizontalalignment='center', bbox={'facecolor': 'white', 'alpha':0.8, 'pad': 2, 'edgecolor':'none'})\n\n\nplt.tight_layout()\nax.axis(\"off\")\n\nplt.show()\n\nC:\\Users\\uursavas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n  warnings.warn(\n\n\nNameError: name 'merged_data' is not defined\n\n\n\n\n\n\n\n\n\n\n# lattice stored in a geo-table\nw = weights.contiguity.Queen.from_dataframe(geojson_data)\nw.transform = \"R\"\nw.neighbors\n\n\n\nC:\\Users\\uursavas\\AppData\\Local\\Temp\\ipykernel_20972\\3870122094.py:3: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n  w = weights.contiguity.Queen.from_dataframe(geojson_data)\n\n\n{0: [36, 41, 57, 61, 46, 63],\n 1: [32, 80, 54, 25, 41],\n 2: [19, 52, 53, 38, 24, 74, 31],\n 3: [17, 37, 59, 75, 44, 30],\n 4: [66, 77, 71, 23],\n 5: [19, 52, 38, 57, 58, 43],\n 6: [64, 11, 30],\n 7: [40, 24, 58, 55],\n 8: [20, 53, 21, 55, 40],\n 9: [48, 50, 18, 52, 22, 10, 31],\n 10: [50, 52, 9, 60, 61],\n 11: [44, 6, 30],\n 12: [42, 45, 78],\n 13: [17, 67, 56, 25, 59, 79],\n 14: [64, 34, 72, 29, 30],\n 15: [65, 18, 51, 20, 53, 31],\n 16: [30, 73, 59, 28, 29, 25],\n 17: [3, 67, 75, 59, 13],\n 18: [65, 9, 42, 78, 15, 22, 26, 31],\n 19: [2, 5, 38, 24, 58],\n 20: [51, 53, 8, 76, 15],\n 21: [8, 27, 70],\n 22: [48, 18, 23, 9, 42, 45],\n 23: [48, 66, 4, 68, 77, 22, 45],\n 24: [2, 19, 7, 74, 55, 58],\n 25: [1, 13, 80, 16, 54, 56, 59, 28],\n 26: [65, 18, 78],\n 27: [49, 21, 70],\n 28: [16, 54, 73, 29, 25],\n 29: [33, 34, 69, 73, 14, 16, 54, 28, 30],\n 30: [64, 3, 6, 11, 44, 14, 16, 59, 29],\n 31: [2, 18, 52, 53, 9, 15],\n 32: [80, 1, 36, 41, 63, 47],\n 33: [34, 69, 72, 29, 62],\n 34: [72, 33, 29, 14],\n 35: [75, 79],\n 36: [0, 32, 63],\n 37: [3, 44],\n 38: [2, 19, 52, 5],\n 39: [49, 51, 70],\n 40: [8, 55, 7],\n 41: [0, 1, 32, 69, 54, 46, 63],\n 42: [18, 22, 12, 45, 78],\n 43: [57, 52, 5],\n 44: [11, 3, 37, 30],\n 45: [68, 22, 23, 42, 12],\n 46: [0, 61, 69, 41, 60, 77],\n 47: [32],\n 48: [50, 22, 23, 9, 77],\n 49: [27, 70, 39],\n 50: [48, 9, 10, 60, 77],\n 51: [65, 20, 39, 76, 15],\n 52: [2, 5, 38, 9, 10, 43, 57, 61, 31],\n 53: [2, 20, 55, 8, 74, 31, 15],\n 54: [1, 69, 41, 28, 29, 25],\n 55: [53, 7, 40, 8, 74, 24],\n 56: [80, 67, 25, 13, 79],\n 57: [0, 52, 5, 43, 61],\n 58: [24, 19, 5, 7],\n 59: [16, 17, 3, 25, 13, 30],\n 60: [50, 77, 10, 61, 46],\n 61: [0, 52, 57, 10, 60, 46],\n 62: [33, 66, 69, 71],\n 63: [0, 41, 32, 36],\n 64: [72, 30, 6, 14],\n 65: [26, 18, 51, 15],\n 66: [4, 68, 23, 71, 62],\n 67: [17, 56, 75, 13, 79],\n 68: [66, 45, 23],\n 69: [33, 71, 41, 77, 46, 54, 29, 62],\n 70: [49, 27, 21, 39],\n 71: [66, 4, 69, 77, 62],\n 72: [64, 33, 34, 14],\n 73: [16, 28, 29],\n 74: [24, 2, 53, 55],\n 75: [17, 3, 67, 35, 79],\n 76: [51, 20],\n 77: [4, 69, 71, 46, 48, 50, 23, 60],\n 78: [18, 26, 42, 12],\n 79: [35, 67, 56, 75, 13],\n 80: [32, 1, 56, 25]}\n\n\n\ngeojson_data[\"2004_lag\"] = weights.spatial_lag.lag_spatial(\n    w, geojson_data[\"2004\"]\n)\n\n\ngeojson_data[\"2021_lag\"] = weights.spatial_lag.lag_spatial(\n    w, geojson_data[\"2021\"]\n)\n\n\n\nmoran = esda.moran.Moran(geojson_data[\"2004\"], w)\n\n\nmoran.I\n\n0.6673411138948363\n\n\n\nmoran1 = esda.moran.Moran(geojson_data[\"2021\"], w)\nmoran.I\n\n0.6673411138948363\n\n\n\nplot_moran(moran);\n\nC:\\Users\\uursavas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\splot\\_viz_esda_mpl.py:354: FutureWarning: \n\n`shade` is now deprecated in favor of `fill`; setting `fill=True`.\nThis will become an error in seaborn v0.14.0; please update your code.\n\n  sbn.kdeplot(moran.sim, shade=shade, color=color, ax=ax, **kwargs)\n\n\n\n\n\n\n\n\n\n\nfrom splot import esda as esdaplot\n\n\nprint(moran2004.I, moran2021.I)\n\nNameError: name 'moran2004' is not defined\n\n\n\nmoran.p_sim\n\n0.001\n\n\n\nlisa = esda.moran.Moran_Local(geojson_data[\"2004\"], w)\n\n\nesdaplot.lisa_cluster(lisa, geojson_data, p=0.01)\n\n\n# Display the figure\nplt.show()\n\n\n\n\n\n\n\n\n\nlisa1 = esda.moran.Moran_Local(geojson_data[\"2021\"], w)\n\n\nesdaplot.lisa_cluster(lisa1, geojson_data, p=0.01)\n\n\n# Display the figure\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>dani_style_informal.html</span>"
    ]
  },
  {
    "objectID": "labs/chen_ntl_spatial_lags.html",
    "href": "labs/chen_ntl_spatial_lags.html",
    "title": "spatial data ugur ursavas xxxx",
    "section": "",
    "text": "import pandas\nimport geopandas\nfrom libpysal import graph\nimport os\nimport geopandas as gpd\n\n\nos.chdir('F:/projects/2024/ursavas_alahmadi_chen/data/ntl_data')\n\n\npanel = (\n    pandas.read_csv(\n        'spatial.csv', \n        encoding = 'ISO-8859-9' # Turkish encoding\n    )\n    .set_index(['asdf_id', 'year'])\n    \n)\n\n\ngeo = gpd.read_file(\"F:/projects/2024/informal/TUR_ADM1.geojson\")\n\n\nw = (\n    graph.Graph.build_contiguity(geo, rook=False)\n    .transform('R')\n)\n\n\nw.neighbors\n\n{0: (36, 41, 46, 57, 61, 63),\n 1: (25, 32, 41, 54, 80),\n 2: (19, 24, 31, 38, 52, 53, 74),\n 3: (17, 30, 37, 44, 59, 75),\n 4: (23, 66, 71, 77),\n 5: (19, 38, 43, 52, 57, 58),\n 6: (11, 30, 64),\n 7: (24, 40, 55, 58),\n 8: (20, 21, 40, 53, 55),\n 9: (10, 18, 22, 31, 48, 50, 52),\n 10: (9, 50, 52, 60, 61),\n 11: (6, 30, 44),\n 12: (42, 45, 78),\n 13: (17, 25, 56, 59, 67, 79),\n 14: (29, 30, 34, 64, 72),\n 15: (18, 20, 31, 51, 53, 65),\n 16: (25, 28, 29, 30, 59, 73),\n 17: (3, 13, 59, 67, 75),\n 18: (9, 15, 22, 26, 31, 42, 65, 78),\n 19: (2, 5, 24, 38, 58),\n 20: (8, 15, 51, 53, 76),\n 21: (8, 27, 70),\n 22: (9, 18, 23, 42, 45, 48),\n 23: (4, 22, 45, 48, 66, 68, 77),\n 24: (2, 7, 19, 55, 58, 74),\n 25: (1, 13, 16, 28, 54, 56, 59, 80),\n 26: (18, 65, 78),\n 27: (21, 49, 70),\n 28: (16, 25, 29, 54, 73),\n 29: (14, 16, 28, 30, 33, 34, 54, 69, 73),\n 30: (3, 6, 11, 14, 16, 29, 44, 59, 64),\n 31: (2, 9, 15, 18, 52, 53),\n 32: (1, 36, 41, 47, 63, 80),\n 33: (29, 34, 62, 69, 72),\n 34: (14, 29, 33, 72),\n 35: (75, 79),\n 36: (0, 32, 63),\n 37: (3, 44),\n 38: (2, 5, 19, 52),\n 39: (49, 51, 70),\n 40: (7, 8, 55),\n 41: (0, 1, 32, 46, 54, 63, 69),\n 42: (12, 18, 22, 45, 78),\n 43: (5, 52, 57),\n 44: (3, 11, 30, 37),\n 45: (12, 22, 23, 42, 68),\n 46: (0, 41, 60, 61, 69, 77),\n 47: (32,),\n 48: (9, 22, 23, 50, 77),\n 49: (27, 39, 70),\n 50: (9, 10, 48, 60, 77),\n 51: (15, 20, 39, 65, 76),\n 52: (2, 5, 9, 10, 31, 38, 43, 57, 61),\n 53: (2, 8, 15, 20, 31, 55, 74),\n 54: (1, 25, 28, 29, 41, 69),\n 55: (7, 8, 24, 40, 53, 74),\n 56: (13, 25, 67, 79, 80),\n 57: (0, 5, 43, 52, 61),\n 58: (5, 7, 19, 24),\n 59: (3, 13, 16, 17, 25, 30),\n 60: (10, 46, 50, 61, 77),\n 61: (0, 10, 46, 52, 57, 60),\n 62: (33, 66, 69, 71),\n 63: (0, 32, 36, 41),\n 64: (6, 14, 30, 72),\n 65: (15, 18, 26, 51),\n 66: (4, 23, 62, 68, 71),\n 67: (13, 17, 56, 75, 79),\n 68: (23, 45, 66),\n 69: (29, 33, 41, 46, 54, 62, 71, 77),\n 70: (21, 27, 39, 49),\n 71: (4, 62, 66, 69, 77),\n 72: (14, 33, 34, 64),\n 73: (16, 28, 29),\n 74: (2, 24, 53, 55),\n 75: (3, 17, 35, 67, 79),\n 76: (20, 51),\n 77: (4, 23, 46, 48, 50, 60, 69, 71),\n 78: (12, 18, 26, 42),\n 79: (13, 35, 56, 67, 75),\n 80: (1, 25, 32, 56)}\n\n\n\nlags = pandas.DataFrame(index=panel.index, columns=panel.columns)\n\nfor year in panel.index.get_level_values('year').unique():\n    for var in lags.columns:\n        vals = panel.loc[pandas.IndexSlice[:, year], var]\n        lags.loc[vals.index, var] = w.lag(vals)\n\n\nlags.to_csv('lagged_ntl_panel.csv')",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>chen_ntl_spatial_lags.html</span>"
    ]
  },
  {
    "objectID": "labs/final_informal.html",
    "href": "labs/final_informal.html",
    "title": "5  Spatial weights matrix and spatial lag",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\nsns.set_context(context=\"paper\", font_scale=1.5, rc=None)\nsns.set(font=\"serif\")\nimport seaborn\n\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\n\nimport libpysal\nfrom libpysal  import weights\nfrom pysal.explore import esda \nimport esda\nfrom esda.moran import Moran, Moran_Local\n\nimport splot\nfrom splot.esda import moran_scatterplot, plot_moran, lisa_cluster\nfrom splot.libpysal import plot_spatial_weights\n\nfrom giddy.directional import Rose\nimport os\n\nfrom numpy.random import seed\nseed(12345)\n\nos.chdir('F:/projects/2024/informal')\n\n\ninformal = pd.read_csv(\"F:/projects/2024/informal/results/informal_spatial.csv\", encoding='unicode_escape')\n\ngeojson_data = gpd.read_file(\"F:/projects/2024/informal/TUR_ADM1.geojson\")\n\nmerged_data = pd.merge(geojson_data, informal, how='left', left_on='asdf_id', right_on='asdf_id')\n\n\nfig, ax = plt.subplots(figsize=(12,8))\nmerged_data.plot(column=\"2004\", scheme='NaturalBreaks', k=5, cmap='coolwarm', legend=True, ax=ax)\nplt.title('Spatial distribution of informal sector (% of GDP) in 2004: Five natural breaks')\nplt.tight_layout()\nax.axis(\"off\")\nplt.show()\n\nC:\\Users\\uursavas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(12,8))\nmerged_data.plot(column=\"2004\", scheme='Quantiles',  cmap='coolwarm', legend=True, ax=ax)\nplt.title('Spatial distribution of informal sector (% of GDP) in 2004: Quantiles')\nplt.tight_layout()\nax.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(12,8))\nmerged_data.plot(column=\"2021\", scheme='NaturalBreaks', k=5, cmap='coolwarm', legend=True, ax=ax)\nplt.title('Spatial distribution of informal sector (% of GDP) in 2021: Five natural breaks')\nplt.tight_layout()\nax.axis(\"off\")\nplt.show()\n\nC:\\Users\\uursavas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(12,8))\nmerged_data.plot(column=\"2021\", scheme='Quantiles',  cmap='coolwarm', legend=True, ax=ax)\nplt.title('Spatial distribution of informal sector (% of GDP) in 2021: Quantiles')\nplt.tight_layout()\nax.axis(\"off\")\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12,8))\nmerged_data.plot(column=\"2004\", scheme='NaturalBreaks', k=5, cmap='coolwarm', legend=True, ax=axes[0,0])\nmerged_data.plot(column=\"2021\", scheme='NaturalBreaks', k=5, cmap='coolwarm', legend=True, ax=axes[0,1])\nmerged_data.plot(column=\"2004\", scheme='Quantiles',  cmap='coolwarm', legend=True, ax=axes[1,0])\nmerged_data.plot(column=\"2021\", scheme='Quantiles',  cmap='coolwarm', legend=True, ax=axes[1,1])\nplt.tight_layout()\naxes[0,0].axis(\"off\")\naxes[0,1].axis(\"off\")\naxes[1,0].axis(\"off\")\naxes[1,1].axis(\"off\")\n\naxes[0,0].title.set_text('Spatial distrib. of informal sec. (% GDP) in 2004: Five natural breaks')\naxes[0,1].title.set_text('Spatial distrib. of informal sec. (% GDP) in 2021: Five natural breaks')\naxes[1,0].title.set_text('Spatial distrib. of informal sec. (% GDP) in 2004: Quantiles')\naxes[1,1].title.set_text('Spatial distrib. of informal sec. (% GDP) in 2021: Quantiles')\nplt.show()\n\nC:\\Users\\uursavas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n  warnings.warn(\nC:\\Users\\uursavas\\AppData\\Local\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n  warnings.warn(\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Load weights matrix\nw_queen = weights.contiguity.Queen.from_dataframe(merged_data)\n\n\n# Row-standardize weights matrix\nw_queen.transform = \"R\"\n\nC:\\Users\\uursavas\\AppData\\Local\\Temp\\ipykernel_19752\\3796823966.py:2: FutureWarning: `use_index` defaults to False but will default to True in future. Set True/False directly to control this behavior and silence this warning\n  w_queen = weights.contiguity.Queen.from_dataframe(merged_data)\n\n\n\n# Create spatial lag variables\nmerged_data[\"w_2004\"] = weights.lag_spatial(w_queen, merged_data[\"2004\"])\nmerged_data[\"w_2021\"] = weights.lag_spatial(w_queen, merged_data[\"2021\"])\n\n\nmerged_data[[\"2004\", \"w_2004\", \"2021\", \"w_2021\"]]\n\n\n\n\n\n\n\n\n2004\nw_2004\n2021\nw_2021\n\n\n\n\n0\n32.246507\n32.285411\n27.963184\n27.976770\n\n\n1\n33.744531\n32.976798\n29.467049\n28.881355\n\n\n2\n32.554150\n31.500792\n28.388501\n27.414615\n\n\n3\n34.154317\n33.724340\n30.042331\n29.336063\n\n\n4\n32.385330\n32.815203\n28.537311\n28.871858\n\n\n...\n...\n...\n...\n...\n\n\n76\n30.397265\n28.646569\n25.600179\n24.339981\n\n\n77\n33.064559\n32.355686\n29.061970\n28.332046\n\n\n78\n32.795890\n31.436861\n27.468281\n27.367597\n\n\n79\n33.526188\n33.762620\n28.986277\n29.301213\n\n\n80\n33.605297\n33.306058\n30.030058\n28.821534\n\n\n\n\n81 rows × 4 columns\n\n\n\n\n## Spatial autocorrelation\n\n\nx2004 = merged_data[\"2004\"]\nx2021 = merged_data[\"2021\"]\n\n\nmoran2004 = Moran(x2004, w_queen)\nmoran2021 = Moran(x2021, w_queen)\n\n\nprint(moran2004.I, moran2021.I)\n\nprint(moran2004.p_sim, moran2021.p_sim)\n\n0.6673411138948363 0.6516556145477524\n0.001 0.001\n\n\n\nfig, ax = plt.subplots(figsize=(6,4))\nmoran_scatterplot(moran2004, zstandard=False, ax = ax)\nax.set_xlabel(\"Informal sector 2004\")\nax.set_ylabel(\"Spatial lag of informal sector 2004\")\nax.set_title(\"Moran's I: 0.667\")\n\nax.text(31,30, 'LL')\nax.text(32.5,33.5, 'HH')\nax.text(33,31, 'HL')\nax.text(29,33, 'LH')\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(figsize=(6,4))\nmoran_scatterplot(moran2021, zstandard=False, ax = ax)\nax.set_xlabel(\"Informal sector 2021\")\nax.set_ylabel(\"Spatial lag of informal sector 2021\")\nax.set_title(\"Moran's I: 0.651\")\n\nax.text(25,26.5, 'LL')\nax.text(29.5,28.2, 'HH')\nax.text(29,26, 'HL')\nax.text(25,29, 'LH')\n\n\nplt.show()\n\n\n\n\n\n\n\n\n\n#Evolution of spatial dependence\n\n\n# Create multidimentional array\ndfa = merged_data.loc[:,'2004':'2021'].values\ndfa\n\narray([[32.24650724, 31.68800442, 31.1363712 , ..., 28.03218968,\n        27.96208341, 27.96318404],\n       [33.74453059, 33.17080523, 32.58001702, ..., 29.37008434,\n        29.40589497, 29.46704928],\n       [32.55414979, 32.06300928, 31.46635918, ..., 28.10038133,\n        28.12354415, 28.3885011 ],\n       ...,\n       [32.7958902 , 32.16115138, 31.45265665, ..., 28.05074082,\n        27.83310122, 27.46828148],\n       [33.52618756, 33.04539777, 32.4438166 , ..., 28.94672984,\n        28.86962828, 28.98627677],\n       [33.60529683, 33.15259018, 32.63714094, ..., 29.88145291,\n        29.92967381, 30.03005795]])\n\n\n\n# Create array of years\nyears = np.arange(2004,2022)\nyears\n\narray([2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014,\n       2015, 2016, 2017, 2018, 2019, 2020, 2021])\n\n\n\nmits = [Moran(cs, w_queen) for cs in dfa.T]\nres = np.array([(m.I, m.EI, m.p_sim, m.z_sim) for m in mits])\n\n\n\nplt.plot(years, res[:, 0])\n\n# Set integer ticks on the x-axis\nplt.xticks(years)\nplt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n\n# Add labels\nplt.xlabel(\"Years\")\nplt.ylabel(\"Moran's I\")\n\n# Show the plot\nplt.show()\n\n\n\n\n\n\n\n\n\n### Evolution of regional disparities\n\n\nsigma = dfa.std(axis=0)\nplt.plot(years, sigma)\nplt.xticks(years)\nplt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n#plt.title(\"Sigma Convergence\")\nplt.ylabel('Stand. Deviation');\n\n\n\n\n\n\n\n\n\nplt.plot(years, res[:,0], label=\"Spatial Dep.\")\nplt.plot(years, sigma,  label=\"Disparities\")\nplt.xticks(years)\nplt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\nplt.legend(bbox_to_anchor=(1.31,1), loc=\"upper right\");\n\n\n\n\n\n\n\n\n\n# create figure and axis objects with subplots()\nfig,ax = plt.subplots()\n# make a plot\nax.plot(years, res[:,0], color=\"royalblue\")\n# set y-axis label\nax.set_ylabel(\"Moran's I\", color=\"royalblue\")\n# twin object for two different y-axis on the sample plot\nax2=ax.twinx()\n# make a plot with different y-axis using second axis object\nax2.plot(years, sigma, color=\"orange\")\nax2.set_ylabel(\"Stand. Deviation\", color=\"darkorange\")\nplt.xticks(years)\nplt.gca().xaxis.set_major_locator(plt.MaxNLocator(integer=True))\nplt.show()\n\n\n\n\n\n\n\n\n\n## LISA scatterplot and map\n\n\nLmoran2004 = Moran_Local(x2004, w_queen)\nLmoran2021 = Moran_Local(x2021, w_queen)\n\n\n# Plot LISA map\nfig, ax = plt.subplots(figsize=(14,12))\nlisa_cluster(Lmoran2004, merged_data, p=0.01, figsize = (16,12),ax=ax)\nplt.title('Spatial clusters in 2004')\nplt.show()\n\n\n\n\n\n\n\n\n\n# Plot LISA map\nfig, ax = plt.subplots(figsize=(14,12))\nlisa_cluster(Lmoran2021, merged_data, p=0.01, figsize = (16,12),ax=ax)\nplt.title('Spatial clusters in 2021')\nplt.show()",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>final_informal.html</span>"
    ]
  }
]